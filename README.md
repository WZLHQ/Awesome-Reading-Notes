TODO list

* [X] undestand beam search and read the code
* [X] undestand KV cache and read the code
* [ ] review several typical attention mechanisms in Transformer
* [ ] implement the basic multi-head attention, grouped-query attention
